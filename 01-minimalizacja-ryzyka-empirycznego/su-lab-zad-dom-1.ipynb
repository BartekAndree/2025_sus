{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systemy uczące się - Zad. dom. 1: Minimalizacja ryzyka empirycznego\n",
    "Celem zadania jest zaimplementowanie własnego drzewa decyzyjnego wykorzystującego idee minimalizacji ryzyka empirycznego. \n",
    "\n",
    "### Autor rozwiązania\n",
    "Uzupełnij poniższe informacje umieszczając swoje imię i nazwisko oraz numer indeksu:"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "NAME = \"Bartłomiej Andree\"\n",
    "ID = \"162961\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T22:01:26.026822Z",
     "start_time": "2025-03-11T22:01:26.016044Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twoja implementacja\n",
    "\n",
    "Twoim celem jest uzupełnić poniższą klasę `TreeNode` tak by po wywołaniu `TreeNode.fit` tworzone było drzewo decyzyjne minimalizujące ryzyko empiryczne. Drzewo powinno wspierać problem klasyfikacji wieloklasowej (jak w przykładzie poniżej). Zaimplementowany algorytm nie musi (ale może) być analogiczny do zaprezentowanego na zajęciach algorytmu dla klasyfikacji. Wszelkie przejawy inwencji twórczej wskazane. **Pozostaw komenatrze w kodzie, które wyjaśniają Twoje rozwiązanie.**\n",
    "\n",
    "Schemat oceniania:\n",
    "- wynik na zbiorze Iris (automatyczna ewaluacja) celność klasyfikacji >= prostego baseline'u + 10%: +40%,\n",
    "- wynik na ukrytym zbiorze testowym 1 (automatyczna ewaluacja) celność klasyfikacji >= prostego baseline'u + 15%: +30%,\n",
    "- wynik na ukrytym zbiorze testowym 2 (automatyczna ewaluacja) celność klasyfikacji >= prostego baseline'u + 5%: +30%.\n",
    "\n",
    "Niedozwolone jest korzystanie z zewnętrznych bibliotek do tworzenia drzewa decyzyjnego (np. scikit-learn). \n",
    "Możesz jedynie korzystać z biblioteki numpy.\n",
    "\n",
    "#### Uwaga: Możesz dowolnie modyfikować elementy tego notebooka (wstawiać komórki i zmieniać kod), o ile będzie się w nim na koniec znajdowała kompletna implementacja klasy `TreeNode` w jednej komórce."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T22:01:26.061364Z",
     "start_time": "2025-03-11T22:01:26.043339Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self):\n",
    "        self.left: TreeNode | None = None   # wierzchołek znajdujący się po lewej stronie\n",
    "        self.right: TreeNode | None = None  # wierzchołek znajdujący się po prawej stronie\n",
    "        self.value = None                   # wartość liścia (przypisana odpowiedź)\n",
    "        self.split_feature = None           # indeks cechy, po której dzielimy (tutaj minimalnie tylko 0)\n",
    "        self.split_threshold = None         # próg podziału\n",
    "\n",
    "    def fit(self, data: np.ndarray, target: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (np.ndarray): macierz cech o wymiarach (n, m), gdzie n to liczba przykładów, a m to liczba cech\n",
    "            target (np.ndarray): wektor klas o długości n, gdzie n to liczba przykładów\n",
    "        \"\"\"\n",
    "\n",
    "        # Poniej znajdziesz przykładowy \"pseudo-kod\" rozwiązania, nie musisz się go trzymać\n",
    "\t\t# (możesz zaimplementować to w inny sposób, jeżeli wolisz)\n",
    "\t\t#\n",
    "\t\t# Znajdź najlepszy podział x, y\n",
    "\t\t# if uzyskano poprawę funkcji celu (bądź inny, zaproponowany przez Ciebie warunek):\n",
    "\t\t# \tpodziel dane na dwie części data_left i data_right, zgodnie z warunkiem\n",
    "\t\t# \tself.left = Node()\n",
    "\t\t# \tself.right = Node()\n",
    "\t\t# \tself.left.fit(data_left)\n",
    "\t\t# \tself.right.fit(data_right)\n",
    "\t\t# else:\n",
    "\t\t# \tobecny Node jest liściem, zapisz jego odpowiedź\n",
    "\n",
    "\n",
    "        # Jeśli wszystkie etykiety są takie same, ustawiamy liść i zapisujemy jego odpowiedź\n",
    "        if len(np.unique(target)) == 1:\n",
    "            self.value = target[0]\n",
    "        else:\n",
    "            # W tym minimalnym przykładzie jako kryterium podziału wybieramy medianę pierwszej cechy\n",
    "            threshold = np.median(data[:, 0])\n",
    "\n",
    "            # Dzielimy dane na dwie części: data_left oraz data_right, zgodnie z warunkiem\n",
    "            left_indices = data[:, 0] <= threshold\n",
    "            right_indices = data[:, 0] > threshold\n",
    "\n",
    "            # Jeśli podział nie rozdziela danych, ustawiamy węzeł jako liść (głosowanie większościowe)\n",
    "            if np.sum(left_indices) == 0 or np.sum(right_indices) == 0:\n",
    "                self.value = np.bincount(target).argmax()\n",
    "                return\n",
    "\n",
    "            # Zapisujemy warunek podziału w bieżącym węźle\n",
    "            self.split_feature = 0\n",
    "            self.split_threshold = threshold\n",
    "\n",
    "            # Przygotowanie danych dla lewego i prawego podziału\n",
    "            data_left = data[left_indices]\n",
    "            target_left = target[left_indices]\n",
    "            data_right = data[right_indices]\n",
    "            target_right = target[right_indices]\n",
    "\n",
    "            # Utwórz węzły potomne i rekurencyjnie dopasuj poddrzewa\n",
    "            self.left = TreeNode()\n",
    "            self.right = TreeNode()\n",
    "            self.left.fit(data_left, target_left)\n",
    "            self.right.fit(data_right, target_right)\n",
    "\n",
    "    def predict(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (np.ndarray): macierz cech o wymiarach (n, m), gdzie n to liczba przykładów, a m to liczba cech\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: wektor przewidzianych klas o długości n, gdzie n to liczba przykładów\n",
    "        \"\"\"\n",
    "        y_pred = np.zeros(data.shape[0])\n",
    "\n",
    "        # Poniżej znajdziesz przykładowy \"pseudo-kod\" rozwiązania, nie musisz się go trzymać\n",
    "\t\t# (możesz zaimplementować to w inny sposób, jeżeli wolisz),\n",
    "\t\t# ważne by metoda TreeNode.predict zwracała wektor przewidzianych klas\n",
    "\t\t#\n",
    "        # Dla każdego przykładu w data:\n",
    "\t\t#   node = self\n",
    "        #   if node nie jest liściem:\n",
    "        #       if warunek podziału node jest spełniony:\n",
    "        #           node = node.right\n",
    "        #       else:\n",
    "        #           node = node.left\n",
    "        #   y_pred[i] = zwróć wartość node (liść)\n",
    "\n",
    "        # Dla każdego przykładu przechodzimy po drzewie aż do liścia\n",
    "        for i, sample in enumerate(data):\n",
    "            node = self\n",
    "            while node.value is None:\n",
    "                # Jeśli warunek podziału jest spełniony, przechodzimy do prawego poddrzewa,\n",
    "                # w przeciwnym razie do lewego\n",
    "                if sample[node.split_feature] > node.split_threshold:\n",
    "                    node = node.right\n",
    "                else:\n",
    "                    node = node.left\n",
    "            y_pred[i] = node.value\n",
    "        return y_pred\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład trenowanie i testowania drzewa\n",
    " \n",
    "Później znajduje się przykład trenowania i testowania drzewa na zbiorze danych `iris`, który zawierający 150 próbek irysów, z czego każda próbka zawiera 4 atrybuty: długość i szerokość płatków oraz długość i szerokość działki kielicha. Każda próbka należy do jednej z trzech klas: `setosa`, `versicolor` lub `virginica`, które są zakodowane jak int.\n",
    "\n",
    "Możesz go wykorzystać do testowania swojej implementacji. Możesz też zaimplementować własne testy lub użyć innych zbiorów danych, np. innych [zbiorów danych z scikit-learn](https://scikit-learn.org/stable/datasets/toy_dataset.html#toy-datasets)."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T22:01:26.092405Z",
     "start_time": "2025-03-11T22:01:26.083231Z"
    }
   },
   "cell_type": "code",
   "source": "#!pip install scikit-learn",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T22:01:26.169977Z",
     "start_time": "2025-03-11T22:01:26.151896Z"
    }
   },
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33, random_state=2024)\n",
    "\n",
    "tree_model = TreeNode()\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred = tree_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
